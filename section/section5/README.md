# 5. 카프카 실전 프로젝트
**프로젝트 개발환경**

- 카프카 클러스터
- openJDK 1.8
- Gradle

## 5.1 웹 페이지 이벤트 적재 파이프라인 생성

<img src="/img/5.1-1.png" width="1000px;">

웹 페이지 사용자 이벤트 수집은 서비스에 영향을 미치지 않으면서도 안정적으로 유지되어야 한다.</br>
이벤트 수집보다 서비스의 정상 동작이 우선되어야 한다.</br>
따라서 이벤트 수집 파이프라인과 서비스의 커플링을 최소화하고 확장성 높은 파이프라인을 만드는 것이 중요하다.</br>
카프카는 예상치 못한 데이터의 급격한 증가가 발생하더라도 안정적으로 운영하는 데에 강점이 있다.</br>
모든 이벤트는 카프카 토픽에 저장되기 때문에, 일단 쌓이면 컨슈머가 자신이 할 수 있는 양만큼 최종 적재 애플리케이션에 저장하면 되기 때문이다.</br>

해당 프로젝트는 웹 페이지에서 생성되는 이벤트들을 분석하기 위해 HDFS 와 엘라스틱서치에 적재하는 파이프라인을 만드는 것을 진행한다.

### 5.1.1 요구 사항

이름을 입력하고 자신이 좋아하는 색상을 고르는 버튼을 클릭하게되면 해당 이벤트와 유저 에이전트 정보를 카프카 토픽으로 전달하고 최종적으로 하둡과 엘라스틱서치에 적재되는 것을 목표로 한다.

### 5.1.2 정책 및 기능 정의

**적재 정책**

적재 파이프라인을 만들 때 가장 처음 결정해야 하는 것은 적재 정책이다.</br>
일부 데이터가 유실이나 중복 적재되어도 무관한 정책이라면 파이프라인의 운영 난이도는 낮아진다.</br>
반면, 데이터가 유실, 중복 없이 정확히 한번(exactly once) 적재되는 정책이라면 파이프라인 운영 난이도는 상당히 올라간다.</br>
정확히 한번 적재가 필요한 경우에는 멱등성 프로듀서를 사용하고 고유한 키를 지원하는 데이터베이스 시스템에 적재하는 것이 확실하다.</br>

예를 들어, RDBMS 인 MySQL 에 unique key 를 가진 테이블을 생성하고 해당 테이블에 insert 하는 적재 파이프라인을 만드는 경우, 컨슈머가 중복해서 insert를 시도하더라도 unique key 로 적재된 데이터가 존재하므로 중복 적재되지 않는다.

이번 프로젝트는 사용자 이벤트를 수집하는 경우이므로 아래와 같이 정책을 정의한다.

- 일부 데이터의 유실 또는 중복 허용
- 안정적으로 끊임없는 적재
- 갑작스럽게 발생하는 많은 데이터양을 허용

**데이터 포멧**

데이터 파이프라인에서 데이터를 담는 용도로 사용되는 데이터 포맷은 다양한 선택지가 있다.

- VO (Value Object) 형태로 객체를 선언하고 직렬화하여 전송하는 방법
    - 단점
        - 보편적이고 편리하지만 프로듀서와 컨슈머에서 동일한 버전의 VO 객체를 선언해서 사용해야 한다
        - 스키마가 변경될 경우(Ex. 변수 추가) 프로듀서와 컨슈머 둘 다 소스코드 업데이트가 필요하므로 비용이 크다.
        - 직렬화 객체는 kafka-console-consumer 명령어를 통해 출력할 경우 내부 데이터를 확인할 수 없으므로 디버깅이 어렵고 디버깅을 위해서는 해당 객체에 특화된 역직렬화 클래스가 필요하다.

데이터 포멧을 선택할 때 두가지를 우선적으로 생각해볼 수 있다.

1. 스키마 변화의 유연성
2. 명령어를 통한 디버깅의 편리성

이 두가지를 만족하는 방법은 JSON(JavaScript Object Notation)이다.</br>
JSON 은 String 으로 선언되어 토픽에 String 또는 ByteArray로 직렬화하여 전송하고 kafka-console-consumer 명령어를 통해 데이터를 출력할 수 있다.</br>
또한, key-value 쌍으로 이루어진 구조를 가지고 있으므로 스키마의 변경에 유연하게 대처할 수 있다.</br>
또한, 이번 프로젝트의 최종 적재되는 타깃 애플리케이션은 HDFS 와 ElasticSearch 이다.</br>
HDFS 에 JSON 포맷으로 파일을 적재하면 Apache Hive 로 external table 을 생성 후 SQL 을 사용하여 필요한 정보를 쿼리로 뽑아낼 수 있다.</br>

**프로듀서**

프로듀서를 운영할 때 가장 처음 고민해야 할 옵션은 ack 를 어떤값으로 설정할지이다.</br>
all 로 설정하게되면 클러스터 또는 네트워크에 이상이 생겼을 경우 복구할 확률이 가장 높지만 그만큼 프로듀서가 클러스터로 데이터를 저장하는데 시간이 오래걸린다.</br>
반면, 1 or 0 으로 설정하여 사용하면 acks 를 all 로 설정했을 때보다 속도는 빠르지만 클러스터에 이상이 생겼을 경우 복구하지 못하고 유실이 발생할 수 있다.</br>

다음 고민은 min.insync.replicas(최소 동기화 리플리카) 설정이다.</br>
acks 를 1 로 설정할 경우 min.insync.replicas 설정을 무시하고 리더 파티션에 지속 적재하므로 따로 설정할 필요가 없다.</br>
acks 를 all 설정으로 운영할 경우에만 min.insync.replicas 설정이 유효하다.</br>

다음은 파티셔너 설정이다.</br>
파티셔너를 활용하면 메시지 키 또는 메시지 값을 기반으로 어떤 파티션으로 전달될지 결정하는 로직을 적용할 수 있다.</br>

다음은 재시도(retries) 설정이다.</br>
클러스터 또는 네트워크 이슈로 인해 데이터가 정상적으로 전송되지 않았을 때 프로듀서는 다시 전송을 시도한다.</br>
프로듀서가 전송을 재시도할 경우 토픽으로 전송된 데이터의 중복이 발생할 수 있고, 전송 시점의 역적으로 인해 전송 순서와 토픽에 적재된 데이터의 순서가 바뀔 수 있다.</br>

다음은 프로듀서의 압축 옵션이다.</br>
프로듀서의 압축은 gzip, snappy, lz4, zstd 중 한개를 고를 수 있다.</br>
압축하면 클러스터에 적재되는 데이터의 총 용량을 줄이고 네트워크의 사용량을 줄이는 데에 효과적이다.</br>
그러나 프로듀서와 컨슈머에서 데이터를 사용할 때 CPU 와 메모리 사용량이 늘어나고 압축을 하지 않았을 때보다 처리량이 줄어들 수 있다.</br>

**토픽**

토픽을 설정할 때 가장 처음 고민할 것은 파티션 개수이다.</br>
파티션 개수는 데이터 처리 순서를 지켜야 하는지 여부에 따라 엄격하게 정할지 말지 결정한다.</br>
하둡 또는 ElasticSearch 에 데이터를 순서대로 적재해야 한다면 파티션 개수를 엄격하게 정해야 한다.</br>
또 이를 구분하는 기준중에 한가지는 이벤트 발생 시간이 데이터에 포함되는지 여부이다.</br>
포함된다면 적재되는 순서가 달라도 시간으로 정렬할 수 있기 때문이다.</br>

다음으로 고민해야 할 점은 메시지 키의 사용 여부이다.</br>
메시지 키를 사용하고 커스텀 프로듀서 파티셔너를 사용하지 않을 경우 메시지 키의 해시값으로 파티션이 분배되기 때문이다.</br>
추 후 파티션이 증가되면 해시값과 파티션의 매칭이 깨지기 때문에 메시지 키를 활용하고 특정 파티션에 할당하는 컨슈머를 운영할 경우 곤란해진다.</br>

다음으로는 복제 개수(replication factor) 이다.</br>
복제 개수가 높으면 높을수록 데이터의 복구 확률이 높아진다.</br>
다만, 복제 개수가 너무 높으면 팔로워 파티션이 데이터를 복제하는 데에 시간이 오래 걸릴 수 있으며 클러스터 전체를 봤을 때 저장되는 데이터의 용량도 그만큼 더 늘어난다.</br>

**컨슈머**

토픽에 저장되어 있는 웹 이벤트를 하둡과 엘라스틱서치에 저장하는 로직을 만드는 방법은 크게 두가지 이다.

- 컨슈머 API 를 사용하여 직접 애플리케이션 개발
    - 장점
        - 컨슈머를 직관적으로 운영하는 가장 좋은 방법
        - 타깃 애플리케이션과 연동하는 라이브러리를 직접 선택하고 적용할 수 있다.
        - 최적화할 수 있는 옵션을 거의 제한 없이 적용할 수 있어서 개발 허용 범위가 넓다.
    - 단점은
        - 반복적으로 생성되는 파이프라인 운영이 필요할 때 확장 가능한 멀티 스레드 애플리케이션을 개발할 때 많은 노력이 든다.
- 커넥트 사용
    - 분산 커넥트를 사용하면 REST API 를 통해 커넥터로 반복적인 파이프라인을 쉽게 생성할 수 있다.
    - 커넥터는 오픈소스(거의 대부분)로도 제공이 되므로 쉽게 사용가능하고 필요로 한다면 직접 개발 가능하다.

선택은 상황에 따라 선택하면 된다.</br>
이미 상용에 분산 커넥트가 구축되어 있다면 싱크 커넥터를 활용하는 것이 좋다.</br>
만약 분산 커넥트가 없다면 구축하는 데에 시간과 인프라 비용이 발생할 수 있으므로 컨슈머 API 를 활용하여 멀티 스레드 자바 애플리케이션을 만들고 배포하여 운영하는 것이 좋다.</br>

### 5.1.3 **기능 구현**

<img src="/img/5.1.3-1.png" width="1000px;">

실습하며 진행할 아키텍처이다.</br>
아키텍처를 구현하기 위해 필요한 작업 리스트이다.

- 로컬 하둡, 엘라스틱서치, 키나바 설치
- 토픽 생성
- 이벤트 수집 웹 페이지 개발
- REST API 프로듀서 애플리케이션 개발
- 하둡 적재 컨슈머 애플리케이션 개발
- 엘라스틱서치 싱크 커넥터 개발

**로컬 하둡, 엘라스틱서치, 키바나 설치**

```jsx
brew install hadoop elasticsearch kibana
```

**토픽 생성**

```jsx
./bin/kafka-topics.sh --create \
--bootstrap-server localhost:9092 \
--replication-factor 2 \
--partitions 3 \
--topic select-color
```

그외 실습은 책 참고…